Google calculated the probability of a user visiting a page through an algorithm called PageRank.PageRange calculates the probability of a user visiting a page by taking into account the number of links that point to the page as well as the style of those links. Having this probability,
Google simulated an arbitrary user and visited a page as often as the user did. Such approach optimizes the resources available to the web crawler by reducing the rate at which the web crawler visits unattractive pages. Through this technique, Google achieved high freshness. Architecturally,
Google used a master-slave architecture with a master server (called URLServer) dispatching URLs to a set of slave nodes. The slave nodes retrieve the assigned pages by downloading them from the web. At its peak, the first implementation of Google reached 100 page downloads per second.